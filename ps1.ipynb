{
  "metadata": {
    "kernelspec": {
      "name": "xpython",
      "display_name": "Python 3.13 (XPython)",
      "language": "python"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "252a302d-68a1-4096-8c91-cea2c4885924",
      "cell_type": "code",
      "source": "# Run this in your first Colab cell to get the data\n!wget http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n!unzip ml-latest-small.zip\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6b114ea8-4cb8-4843-9f4a-0dceba32c849",
      "cell_type": "code",
      "source": "!pip install scikit-surprise\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "83955bf3-acd1-4405-bfe6-6a402d75c800",
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nratings=pd.read_csv('ml-latest-small/ratings.csv')\ndisplay(ratings[['rating']].describe())\nprint(ratings.info())\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a4145ba8-3c53-4de2-9e77-9df2b78b1203",
      "cell_type": "code",
      "source": "display(ratings.head(10))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6c5684a6-4f64-4e0b-82e5-6362bbd6b946",
      "cell_type": "code",
      "source": "import pandas as pd\n\n# Convert timestamp to a readable datetime format\nratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n\n# Now you can see the actual date and time\ndisplay(ratings[['userId', 'movieId', 'rating', 'timestamp']].head(12))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2613a270-3795-412e-9a72-7f1270dccc02",
      "cell_type": "code",
      "source": "movies=pd.read_csv('ml-latest-small/movies.csv')\ndisplay(movies.head(20))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "26866773-07d1-4c95-a980-2a4e978caa9c",
      "cell_type": "code",
      "source": "# 1. First, make sure your timestamps are converted (as we discussed)\nratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n\n# 2. Sort the data by User and Time\n# This ensures the 'last' rows for each user are the most recent ones\nratings = ratings.sort_values(by=['userId', 'timestamp'])\n\n# 3. Define N (the number of ratings to hide from the model per user)\n# N=5 is a common choice for this dataset size\nN = 5\n\n# 4. Create the Test Set (Last N ratings for every user)\ntest_set = ratings.groupby('userId').tail(N)\n\n# 5. Create the Train Set (Everything else)\ntrain_set = ratings.drop(test_set.index)\n\nprint(f\"Training set: {len(train_set)} rows\")\nprint(f\"Testing set: {len(test_set)} rows\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "624b799a-8b69-4faf-9a35-5a8f0d1ac50d",
      "cell_type": "code",
      "source": "# Replace pipes with spaces for a cleaner 'ReelSense' output\nmovies['genres_clean'] = movies['genres'].str.replace('|', ' ', regex=False)\ndisplay(movies[['title', 'genres_clean']].head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e11f9d18-1a10-4ccc-bad4-4bd7bc9a2f52",
      "cell_type": "code",
      "source": "# Create a separate column for every single genre (One-Hot Encoding)\ngenres_split = movies['genres'].str.get_dummies(sep='|')\n\n# Combine it back with your movies dataframe\nmovies_encoded = pd.concat([movies, genres_split], axis=1)\n\n# Now you can see if a movie is 'Action' by checking the Action column\ndisplay(movies_encoded[['title', 'Action', 'Sci-Fi', 'Drama']].head())",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "3334e6a0-77f9-4392-9013-94e5a4dc6763",
      "cell_type": "code",
      "source": "import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 5))\nsns.countplot(x='rating', data=train_set, palette='viridis')\nplt.title('Distribution of User Ratings (Train Set)')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "aefdc445-0885-444d-b810-5d2cd3c56564",
      "cell_type": "code",
      "source": "# Split genres and count frequency\ngenres_df = movies['genres'].str.get_dummies(sep='|')\ngenre_counts = genres_df.sum().sort_values(ascending=False)\n\nplt.figure(figsize=(10, 6))\ngenre_counts.plot(kind='bar', color='skyblue')\nplt.title('Most Popular Movie Genres')\nplt.ylabel('Count')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "65ea667f-d931-4d08-a4ef-9f6122957f04",
      "cell_type": "code",
      "source": "# Force-install the last stable version of NumPy 1.x\n!pip install \"numpy<2\" scikit-surprise --force-reinstall",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b844fd31-243f-4657-83c6-0a2499264209",
      "cell_type": "code",
      "source": "!pip install scikit-surprise\nfrom surprise import SVD, Dataset, Reader, accuracy\nfrom surprise.model_selection import train_test_split\n\n# Load data into Surprise format\nreader = Reader(rating_scale=(0.5, 5.0))\ndata = Dataset.load_from_df(train_set[['userId', 'movieId', 'rating']], reader)\ntrainset_surprise = data.build_full_trainset()\n\n# Train the SVD model (Matrix Factorization)\nsvd_model = SVD(n_factors=100, random_state=42)\nsvd_model.fit(trainset_surprise)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "fa8c0658-b284-464d-ab3a-612ff68fc4c9",
      "cell_type": "code",
      "source": "from surprise import SVD, Dataset, Reader\nprint(\"Surprise imported successfully!\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9434f69e-1270-4fbc-89c2-d9ef9f792497",
      "cell_type": "code",
      "source": "# 1. Merge the training ratings with the encoded movie genres\nuser_genre_matrix = pd.merge(train_set, movies_encoded.drop(['title', 'genres'], axis=1), on='movieId')\n\n# 2. Get the list of genre columns only (ignoring userId, movieId, etc.)\ngenre_cols = genres_split.columns\n\n# 3. Weight the genres by the rating\n# If a user gave a 5.0 to an Action movie, that Action column becomes 5.0 for that row\nfor genre in genre_cols:\n    user_genre_matrix[genre] = user_genre_matrix[genre] * user_genre_matrix['rating']\n\n# 4. Group by User to get their final \"Taste Profile\"\nuser_profiles = user_genre_matrix.groupby('userId')[genre_cols].sum()\n\n# 5. Normalize (Optional but recommended): Scale profiles so they sum to 1\nuser_profiles = user_profiles.div(user_profiles.sum(axis=1), axis=0)\n\nprint(\"User Profiles Created! Sample for User 1:\")\ndisplay(user_profiles.head(1))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4c4b717e-ceec-4ce5-bdde-d75d3c28d200",
      "cell_type": "code",
      "source": "# STEP 4: Creating the profiles\n# We group by userId and sum the genre columns to see what each user likes\nuser_profiles = user_genre_matrix.groupby('userId')[genre_cols].sum()\n\n# We then scale (normalize) the numbers so they are easy to compare\nuser_profiles = user_profiles.div(user_profiles.sum(axis=1), axis=0)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7564f9a4-6bee-43ef-9c86-4686eafd3905",
      "cell_type": "code",
      "source": "# Re-importing after the restart\nimport pandas as pd\nfrom surprise import SVD, Dataset, Reader\n\n# Re-loading data (since it was forgotten)\nratings = pd.read_csv('ml-latest-small/ratings.csv')\n# ... re-run your train/test split code here ...\n\n# NOW run the Step 5 model training\nreader = Reader(rating_scale=(0.5, 5.0))\ndata = Dataset.load_from_df(train_set[['userId', 'movieId', 'rating']], reader)\ntrainset_surprise = data.build_full_trainset()\n\nmodel = SVD()\nmodel.fit(trainset_surprise)\nprint(\"Model trained successfully!\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ee477a17-a719-49aa-96f0-1dd76acdea73",
      "cell_type": "code",
      "source": "def get_hybrid_recommendations(user_id, top_n=10):\n    # Ensure IDs are integers\n    ratings['movieId'] = ratings['movieId'].astype(int)\n    movies['movieId'] = movies['movieId'].astype(int)\n\n    seen = set(ratings[ratings['userId'] == user_id]['movieId'])\n    unseen_df = movies[~movies['movieId'].isin(seen)].copy()\n\n    # Collaborative Score\n    unseen_df['svd_score'] = unseen_df['movieId'].apply(lambda x: model.predict(user_id, x).est)\n\n    # Content Score (Drama/Genre correction)\n    genre_cols = genres_split.columns.tolist()\n    u_weights = user_profiles.loc[user_id].reindex(genre_cols).fillna(0)\n    unseen_df['content_score'] = movies_encoded.loc[unseen_df.index, genre_cols].dot(u_weights) * 5\n\n    # Final Hybrid Score\n    unseen_df['final_score'] = (unseen_df['svd_score'] * 0.7) + (unseen_df['content_score'] * 0.3)\n\n    # Return 3 values: ID, SVD Part, and Content Part (to match your loop)\n    # We sort by the final_score\n    top_df = unseen_df.sort_values(by='final_score', ascending=False).head(top_n)\n\n    # This creates a list of tuples [(id, score1, score2), ...]\n    return list(zip(top_df['movieId'], top_df['svd_score'], top_df['content_score']))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "28732ed3-91cb-4bef-ac83-711403d54043",
      "cell_type": "code",
      "source": "from surprise import accuracy\n\n# 1. Prepare the test set for Surprise\n# We use the 'test_set' we created in Step 2\ntestset_for_surprise = list(zip(test_set['userId'], test_set['movieId'], test_set['rating']))\n\n# 2. Predict ratings for the test set\npredictions = svd_model.test(testset_for_surprise)\n\n# 3. Calculate RMSE\nrmse_score = accuracy.rmse(predictions)\nprint(f\"Model Accuracy (RMSE): {rmse_score:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "d6236f82-bd2a-419c-bc87-9f1cc922f144",
      "cell_type": "code",
      "source": "def precision_at_k(predictions, k=10, threshold=4.0):\n    user_est_true = {}\n    for uid, _, true_r, est, _ in predictions:\n        if uid not in user_est_true:\n            user_est_true[uid] = []\n        user_est_true[uid].append((est, true_r))\n\n    precisions = []\n    for uid, user_ratings in user_est_true.items():\n        # Sort by predicted rating\n        user_ratings.sort(key=lambda x: x[0], reverse=True)\n        # Number of relevant items in top k\n        n_rel_and_rec_k = sum((true_r >= threshold) for (est, true_r) in user_ratings[:k])\n        # Precision = Relevant & Recommended / Recommended\n        precisions.append(n_rel_and_rec_k / k)\n\n    return sum(precisions) / len(precisions)\n\np_at_10 = precision_at_k(predictions, k=10)\nprint(f\"Precision at 10: {p_at_10:.2%}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "feff7c54-81ea-4cdf-8e09-fd801bda696b",
      "cell_type": "code",
      "source": "def get_explanation(user_id, movie_id):\n    # 1. Get the genres for the specific movie\n    # We split by the pipe symbol we discussed earlier\n    movie_genres = set(movies[movies['movieId'] == movie_id]['genres'].iloc[0].split('|'))\n\n    # 2. Find the user's favorite genre from their profile (Step 4)\n    # This identifies the column with the highest weight for that user\n    user_top_genre = user_profiles.loc[user_id].idxmax()\n\n    # 3. Create the natural language reason\n    if user_top_genre in movie_genres:\n        return f\"Because you are a big fan of {user_top_genre} movies!\"\n    else:\n        # Fallback: Find any genre they have in common\n        # This uses simple set intersection\n        common = list(movie_genres.intersection(set(user_profiles.columns[user_profiles.loc[user_id] > 0])))\n        if common:\n            return f\"Matches your interest in {common[0]}.\"\n        else:\n            return \"Recommended based on similar users' high ratings.\"",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "86e82462-40d1-4a63-9116-3e94abee9156",
      "cell_type": "code",
      "source": "# 1. Filter for User 610's 5-star ratings\nf = ratings[(ratings['userId'] == 100) & (ratings['rating'] == 5.0)]\n\n# 2. Merge with your encoded genres\nmerged_data = pd.merge(f, movies_encoded, on='movieId')\n\n# 3. Dynamically get all genre columns (everything except the basic info)\n# This ensures we don't miss \"Horror\", \"Musical\", \"Western\", etc.\nall_cols = ['userId', 'movieId', 'title', 'rating'] + list(genres_split.columns)\n\n# 4. Display the full table\ndisplay(merged_data[all_cols])",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f9ea9e19-4d10-44ae-9ad0-cf9fec3f3c52",
      "cell_type": "code",
      "source": "print(len(train_set[train_set['userId'] == 340]))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "b793d4cf-93fa-4707-a329-e47cc73250c0",
      "cell_type": "code",
      "source": "import ipywidgets as widgets\nfrom IPython.display import display, HTML\n\n# 1. The Corrected Logic Function\ndef get_hybrid_recommendations(user_id, top_n=10):\n    # Ensure IDs are integers for matching\n    ratings['movieId'] = ratings['movieId'].astype(int)\n    movies['movieId'] = movies['movieId'].astype(int)\n\n    # Identify unseen movies\n    seen = set(ratings[ratings['userId'] == user_id]['movieId'])\n    unseen_df = movies[~movies['movieId'].isin(seen)].copy()\n\n    # A. SVD Part (Collaborative)\n    unseen_df['svd_score'] = unseen_df['movieId'].apply(lambda x: model.predict(user_id, x).est)\n\n    # B. Content Part (Genre Correction for User 610/450)\n    genre_cols = genres_split.columns.tolist()\n    u_weights = user_profiles.loc[user_id].reindex(genre_cols).fillna(0)\n    unseen_df['content_score'] = movies_encoded.loc[unseen_df.index, genre_cols].dot(u_weights) * 5\n\n    # C. Hybrid Formula\n    unseen_df['final_score'] = (unseen_df['svd_score'] * 0.9) + (unseen_df['content_score'] * 0.1)\n\n    top_df = unseen_df.sort_values(by='final_score', ascending=False).head(top_n)\n\n    # RETURN THREE VALUES (Fixes the ValueError)\n    return list(zip(top_df['movieId'], top_df['svd_score'], top_df['content_score']))\n\n# 2. The UI and Display Cell\nuser_input = widgets.IntText(value=1, description='User ID:')\nbutton = widgets.Button(description=\"Get Recommendations\", button_style='info')\noutput = widgets.Output()\n\ndef on_button_clicked(b):\n    with output:\n        output.clear_output()\n        uid = user_input.value\n\n        try:\n            # We are now unpacking EXACTLY 3 values: m_id, pred_score, match_score\n            recommendations = get_hybrid_recommendations(uid)\n\n            display(HTML(f\"<h3>--- ReelSense Top 10 for User {uid} ---</h3>\"))\n\n            for i, (m_id, pred_score, match_score) in enumerate(recommendations):\n                title = movies[movies['movieId'] == m_id]['title'].values[0]\n                final_score = (0.7 * pred_score) + (0.3 * match_score)\n\n                # Dynamic Explanation\n                genre_cols = genres_split.columns.tolist()\n                m_genres = movies_encoded[movies_encoded['movieId'] == m_id][genre_cols].iloc[0]\n                u_prof = user_profiles.loc[uid].reindex(genre_cols).fillna(0)\n                top_genre = (m_genres * u_prof).idxmax()\n\n                display(HTML(f\"\"\"\n                    <div style=\"border-left: 5px solid #2196F3; padding: 10px; margin: 5px; background-color: #f1f1f1; border-radius: 5px;\">\n                        <b style=\"color: #333;\">{i+1}. {title}</b><br>\n                        <span style=\"color: #555; font-size: 0.9em;\">Match Reason: Strong affinity for <b>{top_genre}</b> movies.</span><br>\n                        <small style=\"color: #888;\">Strength: {final_score:.2f} | SVD: {pred_score:.1f} | Genre Match: {match_score:.1f}</small>\n                    </div>\n                \"\"\"))\n        except Exception as e:\n            print(f\"Error encountered: {e}\")\n            print(\"Action: Ensure your SVD model and user_profiles cells have been run.\")\n\nbutton.on_click(on_button_clicked)\ndisplay(widgets.VBox([user_input, button, output]))",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}